# -*- coding: utf-8 -*-
"""Dorne_Detection.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/11swP6U-pDi2Y8n0642hcpTSlHbobu0YZ

## Not rellevant anymore
"""

!pip install pydub

from pydub import AudioSegment
from pydub.utils import make_chunks

my_audio = AudioSegment.from_file("DREGON_free-flight_nosource_room1.wav", "wav")

chunks_length_in_ms = 1000

chunks = make_chunks(my_audio, chunks_length_in_ms)

for i, chunk in enumerate(chunks):
  chunk_name = "DREGON_free-flight_nosource_room1-{}.wav".format(i)
  print("exporting " + chunk_name)
  chunk.export(chunk_name, format="wav")

!pip install librosa

import librosa
y, sr = librosa.load("DREGON_free-flight_nosource_room1-71.wav", mono=True, duration=30)
chroma_stft = librosa.feature.chroma_stft(y=y, sr=sr)
print(chroma_stft)

import numpy as np
spec_cent = librosa.feature.spectral_centroid(y=y, sr=sr)
print(spec_cent)
print(np.mean(spec_cent))

from pydub import AudioSegment
import os
from pathlib import Path

def chunk_audio_file(input_file, chunk_length_ms=1000, output_dir="chunks"):
    """
    Divide audio file into chunks and save them to a directory

    Args:
        input_file (str): Path to input audio file
        chunk_length_ms (int): Length of chunks in milliseconds
        output_dir (str): Directory to save chunks
    """
    # Create output directory if it doesn't exist
    Path(output_dir).mkdir(parents=True, exist_ok=True)

    # Load audio file
    audio = AudioSegment.from_wav(input_file)

    # Get filename without extension for naming chunks
    base_filename = os.path.splitext(os.path.basename(input_file))[0]

    # Split audio into chunks
    chunks = [audio[i:i + chunk_length_ms]
             for i in range(0, len(audio), chunk_length_ms)]

    # Export chunks
    chunk_files = []
    for i, chunk in enumerate(chunks):
        # Create chunk filename with padding for proper sorting
        chunk_name = f"{base_filename}-chunk_{i:04d}.wav"
        chunk_path = os.path.join(output_dir, chunk_name)

        print(f"Exporting {chunk_path}")
        chunk.export(chunk_path, format="wav")
        chunk_files.append(chunk_path)

    return chunk_files

# Example usage
input_file = "DREGON_free-flight_nosource_room1.wav"
output_directory = "drone_chunks"  # Directory where chunks will be saved
chunk_length = 1000  # 1 second chunks

# Create chunks and get list of chunk files
chunk_files = chunk_audio_file(
    input_file=input_file,
    chunk_length_ms=chunk_length,
    output_dir=output_directory
)

# # Print all created chunk files
# print("\nCreated chunks:")
# for chunk_file in chunk_files:
#     print(chunk_file)

# # Example of how to iterate over chunks later
# print("\nIterating over chunks:")
# for chunk_file in sorted(Path(output_directory).glob("*.wav")):
#     #print(f"Processing {chunk_file}")
#     # Add your processing code here
#     # For example:
#     # audio = AudioSegment.from_wav(chunk_file)
#     # Do something with the audio...

import pandas as pd

# #def iterate_chunks_pathlib(directory="drone_chunks"):
# def iterate_chunks_pathlib(directory="drone_chunks", output_file="features.csv"):
#     features_list = []
#     # Get all .wav files in directory
#     chunk_path = Path(directory)
#     for chunk_file in sorted(chunk_path.glob("*.wav")):
#         # print(f"Processing {chunk_file}")
#         # Load audio data
#         #audio, sr = librosa.load(str(chunk_file))
#         y, sr = librosa.load(chunk_file, mono=True, duration=30)

#         chroma_stft = librosa.feature.chroma_stft(y=y, sr=sr)
#         chroma_stft_mean = np.mean(chroma_stft)
#         spec_cent = librosa.feature.spectral_centroid(y=y, sr=sr)
#         spec_cent_mean = np.mean(spec_cent)
#         spec_bw= librosa.feature.spectral_bandwidth(y=y, sr=sr)
#         spec_bw_mean = np.mean(spec_bw)
#         rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr)
#         rolloff_mean = np.mean(rolloff)
#         zsr = librosa.feature.zero_crossing_rate(y)
#         zsr_mean = np.mean(zsr)
#         #mfcc = librosa.feature.mfcc(y=y, sr=sr)

#         # Create a dictionary of features for this file
#         features_dict = {
#             'filename': chunk_file.name,
#             'chroma_stft_mean': chroma_stft_mean,
#             'spectral_centroid_mean': spec_cent_mean,
#             'spectral_bandwidth_mean': spec_bw_mean,
#             'rolloff_mean': rolloff_mean,
#             'zero_crossing_rate_mean': zsr_mean
#         }

#         # Append to our list of features
#         features_list.append(features_dict)

#     # Convert to DataFrame
#     df = pd.DataFrame(features_list)

#     # Save to CSV in the same directory
#     output_path = os.path.join(directory, output_file)
#     df.to_csv(output_path, index=False)
#     print(f"\nFeatures saved to {output_path}")

#     return df.head()

# iterate_chunks_pathlib(directory="drone_chunks", output_file="features.csv")

# from pydub import AudioSegment
# import os
# from pathlib import Path

# def chunk_audio_file(input_file, chunk_length_ms=10000, output_dir="chunks"):
#     """
#     Divide audio file into chunks and save them to a directory

#     Args:
#         input_file (str): Path to input audio file
#         chunk_length_ms (int): Length of chunks in milliseconds
#         output_dir (str): Directory to save chunks
#     """
#     # Create output directory if it doesn't exist
#     Path(output_dir).mkdir(parents=True, exist_ok=True)

#     # Load audio file
#     audio = AudioSegment.from_wav(input_file)

#     # Get filename without extension for naming chunks
#     base_filename = os.path.splitext(os.path.basename(input_file))[0]

#     # Split audio into chunks
#     chunks = [audio[i:i + chunk_length_ms]
#              for i in range(0, len(audio), chunk_length_ms)]

#     # Export chunks
#     chunk_files = []
#     for i, chunk in enumerate(chunks):
#         # Create chunk filename with padding for proper sorting
#         chunk_name = f"{base_filename}-chunk_{i:04d}.wav"
#         chunk_path = os.path.join(output_dir, chunk_name)

#         #print(f"Exporting {chunk_path}")
#         chunk.export(chunk_path, format="wav")
#         chunk_files.append(chunk_path)

#     return chunk_files

# import os
# import zipfile
# import tempfile
# import librosa
# import numpy as np
# import pandas as pd

# def extract_features_from_wav(wav_path):
#     """
#     Extract audio features from a single WAV file

#     Args:
#         wav_path (str): Path to WAV file

#     Returns:
#         dict: Extracted audio features
#     """
#     y, sr = librosa.load(wav_path, mono=True, duration=30)

#     return {
#         'filename': os.path.basename(wav_path),
#         'chroma_stft_mean': np.mean(librosa.feature.chroma_stft(y=y, sr=sr)),
#         'spectral_centroid_mean': np.mean(librosa.feature.spectral_centroid(y=y, sr=sr)),
#         'spectral_bandwidth_mean': np.mean(librosa.feature.spectral_bandwidth(y=y, sr=sr)),
#         'rolloff_mean': np.mean(librosa.feature.spectral_rolloff(y=y, sr=sr)),
#         'zero_crossing_rate_mean': np.mean(librosa.feature.zero_crossing_rate(y=y))
#     }

# def process_zip_folders(zip_folder_path):
#     """
#     Process WAV files from ZIP folders in a directory

#     Args:
#         zip_folder_path (str): Path to directory containing ZIP folders

#     Returns:
#         pandas.DataFrame: DataFrame with extracted features
#     """
#     all_features = []

#     # Iterate through all ZIP files in the directory
#     for zip_filename in os.listdir(zip_folder_path):
#         if zip_filename.endswith('.zip'):
#             zip_path = os.path.join(zip_folder_path, zip_filename)

#             # Create temporary directory to extract files
#             with tempfile.TemporaryDirectory() as temp_dir:
#                 # Extract ZIP contents
#                 with zipfile.ZipFile(zip_path, 'r') as zip_ref:
#                     zip_ref.extractall(temp_dir)

#                 # Find and process WAV files
#                 for root, dirs, files in os.walk(temp_dir):
#                     for file in files:
#                         if file.endswith('.wav'):
#                             wav_path = os.path.join(root, file)
#                             try:
#                                 features = extract_features_from_wav(wav_path)
#                                 features['zip_source'] = zip_filename
#                                 all_features.append(features)
#                                 print(f"Processed: {wav_path}")
#                             except Exception as e:
#                                 print(f"Error processing {wav_path}: {e}")

#     # Convert features to DataFrame
#     features_df = pd.DataFrame(all_features)

#     # Save to CSV in the ZIP folder directory
#     output_path = os.path.join(zip_folder_path, 'audio_features.csv')
#     features_df.to_csv(output_path, index=False)
#     print(f"\nFeatures saved to {output_path}")

#     return features_df

# # Example usage
# if __name__ == "__main__":
#     #zip_folder_directory = "path/to/your/zip/folders"
#     zip_folder_names = ['']
#     features_df = process_zip_folders(zip_folder_directory)
#     print("\nFirst few rows of extracted features:")
#     print(features_df.head())

# !pip install pydub

# import os
# import zipfile
# import tempfile
# import librosa
# import numpy as np
# import pandas as pd
# from pathlib import Path
# from pydub import AudioSegment

# def chunk_audio_file(label, input_file, chunk_length_ms=10000, output_dir="chunks"):
#     """
#     Divide audio file into chunks and save them to a directory

#     Args:
#         input_file (str): Path to input audio file
#         chunk_length_ms (int): Length of chunks in milliseconds
#         output_dir (str): Directory to save chunks
#     """
#     # Create output directory if it doesn't exist
#     Path(output_dir).mkdir(parents=True, exist_ok=True)

#     # Load audio file
#     audio = AudioSegment.from_wav(input_file)

#     # Get filename without extension for naming chunks
#     base_filename = os.path.splitext(os.path.basename(input_file))[0]

#     # Split audio into chunks
#     chunks = [audio[i:i + chunk_length_ms]
#              for i in range(0, len(audio), chunk_length_ms)]

#     # Export chunks
#     chunk_files = []
#     for i, chunk in enumerate(chunks):
#         # Create chunk filename with padding for proper sorting
#         chunk_name = f"{base_filename}-chunk_{i:04d}.wav"
#         chunk_path = os.path.join(output_dir, chunk_name)

#         chunk.export(chunk_path, format="wav")
#         chunk_files.append(chunk_path)

#     return chunk_files

# def extract_features_from_wav(wav_path):
#     """
#     Extract audio features from a single WAV file

#     Args:
#         wav_path (str): Path to WAV file

#     Returns:
#         dict: Extracted audio features
#     """
#     y, sr = librosa.load(wav_path, mono=True, duration=30)

#     return {
#         'filename': os.path.basename(wav_path),
#         'chroma_stft_mean': np.mean(librosa.feature.chroma_stft(y=y, sr=sr)),
#         'spectral_centroid_mean': np.mean(librosa.feature.spectral_centroid(y=y, sr=sr)),
#         'spectral_bandwidth_mean': np.mean(librosa.feature.spectral_bandwidth(y=y, sr=sr)),
#         'rolloff_mean': np.mean(librosa.feature.spectral_rolloff(y=y, sr=sr)),
#         'zero_crossing_rate_mean': np.mean(librosa.feature.zero_crossing_rate(y=y)),
#         'label': label
#       }

# def process_zip_folders(label, zip_folder_path, chunk_length_ms=10000):
#     """
#     Process WAV files from ZIP folders, chunk them, and extract features

#     Args:
#         zip_folder_path (str): Path to directory containing ZIP folders
#         chunk_length_ms (int): Length of chunks in milliseconds

#     Returns:
#         pandas.DataFrame: DataFrame with extracted features
#     """
#     all_features = []

#     # Create a main output directory for all processed files
#     output_base_dir = os.path.join(zip_folder_path, 'processed_audio')
#     os.makedirs(output_base_dir, exist_ok=True)

#     # Iterate through all ZIP files in the directory
#     for zip_filename in os.listdir(zip_folder_path):
#         if zip_filename.endswith('.zip'):
#             zip_path = os.path.join(zip_folder_path, zip_filename)

#             # Create temporary directory to extract files
#             with tempfile.TemporaryDirectory() as temp_dir:
#                 # Extract ZIP contents
#                 with zipfile.ZipFile(zip_path, 'r') as zip_ref:
#                     zip_ref.extractall(temp_dir)

#                 # Find and process WAV files
#                 for root, dirs, files in os.walk(temp_dir):
#                     for file in files:
#                         if file.endswith('.wav'):
#                             wav_path = os.path.join(root, file)

#                             try:
#                                 # Create chunks directory for this WAV file
#                                 chunks_dir = os.path.join(output_base_dir, f"{os.path.splitext(file)[0]}_chunks")

#                                 # Chunk the audio file
#                                 chunk_files = chunk_audio_file(
#                                     wav_path,
#                                     chunk_length_ms=chunk_length_ms,
#                                     output_dir=chunks_dir
#                                 )

#                                 # Extract features for each chunk
#                                 for chunk_file in chunk_files:
#                                     features = extract_features_from_wav(chunk_file)
#                                     features['zip_source'] = zip_filename
#                                     features['original_wav'] = file
#                                     all_features.append(features)
#                                     print(f"Processed chunk: {chunk_file}")

#                             except Exception as e:
#                                 print(f"Error processing {wav_path}: {e}")

#     # Convert features to DataFrame
#     features_df = pd.DataFrame(all_features)

#     # Save to CSV in the base output directory
#     output_path = os.path.join(output_base_dir, 'audio_chunk_features.csv')
#     features_df.to_csv(output_path, index=False)
#     print(f"\nFeatures saved to {output_path}")

#     return features_df

# # Example usage
# if __name__ == "__main__":
#     #zip_folder_directory = "/content/zip_file_folder"
#     zip_folder_directory = "/content/Drone_noise"
#     #zip_folder_names = ['DREGON_free-flight_speech-high_room1.zip', "DREGON_free-flight_speech-low_room1.zip"]
#     label = "Drone"
#     features_df = process_zip_folders(label, zip_folder_directory, chunk_length_ms=10000)
#     #features_df = process_zip_folders(zip_folder_names, chunk_length_ms=10000)
#     print("\nFirst few rows of extracted features:")
#     print(features_df.head())

"""#START

"""

!pip install pydub

"""ZIP UPLOAD AND FEATURES EXTRACTIONS"""

import os
import zipfile
import tempfile
import librosa
import numpy as np
import pandas as pd
from pathlib import Path
from pydub import AudioSegment

def chunk_audio_file(input_file, chunk_length_ms=10000, output_dir="chunks"):
    """
    Divide audio file into chunks and save them to a directory
    """
    Path(output_dir).mkdir(parents=True, exist_ok=True)

    audio = AudioSegment.from_wav(input_file)
    base_filename = os.path.splitext(os.path.basename(input_file))[0]

    chunks = [audio[i:i + chunk_length_ms]
             for i in range(0, len(audio), chunk_length_ms)]

    chunk_files = []
    for i, chunk in enumerate(chunks):
        chunk_name = f"{base_filename}-chunk_{i:04d}.wav"
        chunk_path = os.path.join(output_dir, chunk_name)

        chunk.export(chunk_path, format="wav")
        chunk_files.append(chunk_path)

    return chunk_files

def extract_features_from_wav(label, wav_path):
    """
    Extract audio features from a single WAV file
    """
    y, sr = librosa.load(wav_path, mono=True, duration=30)

    # Extract MFCC features
    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)
    n_mfcc = 13
    # Add MFCC features to the dictionary
    mfcc_features = {}
    for i in range(n_mfcc):
        mfcc_features[f'mfcc{i+1}_mean'] = np.mean(mfcc[i])
        mfcc_features[f'mfcc{i+1}_std'] = np.std(mfcc[i])

    rest_of_the_features = {
        'filename': os.path.basename(wav_path),
        'chroma_stft_mean': np.mean(librosa.feature.chroma_stft(y=y, sr=sr)),
        'spectral_centroid_mean': np.mean(librosa.feature.spectral_centroid(y=y, sr=sr)),
        'spectral_bandwidth_mean': np.mean(librosa.feature.spectral_bandwidth(y=y, sr=sr)),
        'rolloff_mean': np.mean(librosa.feature.spectral_rolloff(y=y, sr=sr)),
        'zero_crossing_rate_mean': np.mean(librosa.feature.zero_crossing_rate(y=y)),
        'label': label
    }

    # Combine all features
    all_features = {**rest_of_the_features, **mfcc_features}

    return all_features

    # return {
    #     'filename': os.path.basename(wav_path),
    #     'chroma_stft_mean': np.mean(librosa.feature.chroma_stft(y=y, sr=sr)),
    #     'spectral_centroid_mean': np.mean(librosa.feature.spectral_centroid(y=y, sr=sr)),
    #     'spectral_bandwidth_mean': np.mean(librosa.feature.spectral_bandwidth(y=y, sr=sr)),
    #     'rolloff_mean': np.mean(librosa.feature.spectral_rolloff(y=y, sr=sr)),
    #     'zero_crossing_rate_mean': np.mean(librosa.feature.zero_crossing_rate(y=y)),
    #     'label': label
    # }

def process_single_zip_folder(label, zip_path, chunk_length_ms=10000):
    """
    Process WAV files from a single ZIP folder, chunk them, and extract features
    """
    all_features = []

    # Create output directories
    output_base_dir = os.path.join(os.path.dirname(zip_path), 'processed_audio')
    os.makedirs(output_base_dir, exist_ok=True)

    # Extract ZIP contents to temporary directory
    with tempfile.TemporaryDirectory() as temp_dir:
        with zipfile.ZipFile(zip_path, 'r') as zip_ref:
            zip_ref.extractall(temp_dir)

        # Find and process WAV files
        for root, dirs, files in os.walk(temp_dir):
            for file in files:
                if file.endswith('.wav'):
                    wav_path = os.path.join(root, file)

                    try:
                        # Create chunks directory for this WAV file
                        chunks_dir = os.path.join(output_base_dir, f"{os.path.splitext(file)[0]}_chunks")

                        # Chunk the audio file
                        chunk_files = chunk_audio_file(
                            wav_path,
                            chunk_length_ms=chunk_length_ms,
                            output_dir=chunks_dir
                        )

                        # Extract features for each chunk
                        for chunk_file in chunk_files:
                            features = extract_features_from_wav(label, chunk_file)
                            features['original_wav'] = file
                            all_features.append(features)
                            #print(f"Processed chunk: {chunk_file}")

                    except Exception as e:
                        print(f"Error processing {wav_path}: {e}")

    # Convert features to DataFrame
    features_df = pd.DataFrame(all_features)

    # Save to CSV in the base output directory
    output_path = os.path.join(output_base_dir, 'audio_chunk_features.csv')
    features_df.to_csv(output_path, index=False)
    print(f"\nFeatures saved to {output_path}")

    return features_df

# Example usage
if __name__ == "__main__":
    zip_file_path = "/content/Drone_noise/drone_new.zip"
    label = "drone"
    features_df = process_single_zip_folder(label, zip_file_path, chunk_length_ms=1000)
    print("\nFirst few rows of extracted features:")
    print(features_df.head())

# Example usage
if __name__ == "__main__":
    zip_file_path = "/content/NO_Drone_noise/no_drone_outside_2.zip"
    label = "NO_drone"
    features_df = process_single_zip_folder(label, zip_file_path, chunk_length_ms=1000)
    print("\nFirst few rows of extracted features:")
    print(features_df.head())

"""CSV UPLOAD"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
#from sklearn.preprocessing import StandardScaler

# Load datasets
drone_df = pd.read_csv('drone_features_lab.csv')
no_drone_df = pd.read_csv('no_drone_features_original.csv')

# Add label column (if not already done)
drone_df['label'] = 1  # 1 for drone
no_drone_df['label'] = 0  # 0 for no drone

drone_df.head()

# drone_df.drop(columns=["filename", "original_wav"])
# no_drone_df.drop(columns=["filename", "original_wav"])

"""DATA ARAINGING

"""

drone_df = drone_df.drop(columns=["filename", "original_wav"])
no_drone_df = no_drone_df.drop(columns=["filename", "original_wav"])
# Combine datasets
combined_df = pd.concat([drone_df, no_drone_df], ignore_index=True)

# Shuffle the data
combined_df = combined_df.sample(frac=1).reset_index(drop=True)

# Separate features and labels
X = combined_df.drop('label', axis=1)
y = combined_df['label']

column_names = X.columns
print(column_names)

print(y.head())
# Split into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

print(combined_df.shape[0])
combined_df.head()
# # Scale features
# scaler = StandardScaler()
# X_train_scaled = scaler.fit_transform(X_train)
# X_test_scaled = scaler.transform(X_test)

X.head()

y.head()

print(y.value_counts())

# # Scale features
# scaler = StandardScaler()
# X_train_scaled = scaler.fit_transform(X_train)
# X_test_scaled = scaler.transform(X_test)

"""Rendom Forest"""

from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix

# Train a Random Forest Classifier
clf_rf = RandomForestClassifier(n_estimators=100, random_state=42)
#clf.fit(X_train_scaled, y_train)
clf_rf.fit(X_train, y_train)

# Evaluate the model
# y_pred = clf.predict(X_test_scaled)
y_pred = clf_rf.predict(X_test)
print(classification_report(y_test, y_pred))
print(confusion_matrix(y_test, y_pred))

# Predict on test data
# y_pred = clf.predict(X_test_scaled)
#y_pred = clf.predict(X_test)

# Evaluation metrics
from sklearn.metrics import (
    accuracy_score,
    precision_score,
    recall_score,
    f1_score,
    confusion_matrix
)

print("Accuracy:", accuracy_score(y_test, y_pred))
print("Precision:", precision_score(y_test, y_pred))
print("Recall:", recall_score(y_test, y_pred))
print("F1 Score:", f1_score(y_test, y_pred))
print("\nConfusion Matrix:\n", confusion_matrix(y_test, y_pred))

# # Optional: Test on new data
# new_data_scaled = scaler.transform(X_test)
# predictions = clf.predict(new_data_scaled)

"""SVM MODEL"""

from sklearn import svm

clf_svm = svm.SVC(probability=True)
# clf.fit(X_train_scaled, y_train)
clf_svm.fit(X_train, y_train)

# Evaluate the model
# y_pred = clf.predict(X_test_scaled)
y_pred = clf_svm.predict(X_test)
print(classification_report(y_test, y_pred))
print(confusion_matrix(y_test, y_pred))

# Predict on test data
# y_pred = clf.predict(X_test_scaled)
#y_pred = clf.predict(X_test)

# Evaluation metrics
from sklearn.metrics import (
    accuracy_score,
    precision_score,
    recall_score,
    f1_score,
    confusion_matrix
)

print("Accuracy:", accuracy_score(y_test, y_pred))
print("Precision:", precision_score(y_test, y_pred))
print("Recall:", recall_score(y_test, y_pred))
print("F1 Score:", f1_score(y_test, y_pred))
print("\nConfusion Matrix:\n", confusion_matrix(y_test, y_pred))

# # Optional: Test on new data
# new_data_scaled = scaler.transform(X_test)
# predictions = clf.predict(new_data_scaled)

"""## Using the model"""

!pip install pydub

import joblib

joblib.dump(clf_svm, 'drone_detector_model.joblib')

"""RECORDING TETS"""

import matplotlib.pyplot as plt
import numpy as np
import wave

def plot_audio_signal_and_prediction(audio_path, prediction):
  # Load and process the wave file
  spf = wave.open(audio_path, "r")

  # Extract Raw Audio from Wav File
  signal = spf.readframes(-1)
  signal = np.frombuffer(signal, np.int16)  # Updated method
  fs = spf.getframerate()

  # Normalize the signal to range [-1, 1]
  signal = signal / np.max(np.abs(signal))

  # Time for the audio signal
  Time = np.linspace(0, len(signal) / fs, num=len(signal))

  # Prediction list (scaled to match the signal length)
  # prediction = [1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0]
  prediction_time = np.linspace(0, len(signal) / fs, num=len(prediction))  # Align with audio time

  # Upsample the prediction array to match the length of the signal
  upsampled_prediction = np.interp(Time, prediction_time, prediction)

  # # Plot both graphs
  # plt.figure(figsize=(12, 6))
  # plt.plot(Time, signal, label="Normalized Audio Signal", color="blue")
  # plt.plot(Time, upsampled_prediction, label="Drone Detection", color="red", linewidth=2)
  # Plot both graphs
  plt.figure(figsize=(12, 6))
  plt.plot(Time, signal, label="Audio Signal", color="blue")
  plt.step(prediction_time, prediction, where='post', label="Drone Detection", color="red")

  # Add labels, legend, and grid
  plt.title("Normalized Audio Signal and Drone Detection")
  plt.xlabel("Time (seconds)")
  plt.ylabel("Normalized Amplitude / Detection")
  plt.legend()
  plt.grid(True, which='both', linestyle='--', linewidth=0.5)
  plt.ylim(-1.5, 1.5)  # Set consistent y-axis limits

import librosa
import numpy as np
import pandas as pd
from pathlib import Path
from pydub import AudioSegment
import os

def chunk_audio_file(input_file, chunk_length_ms=10000, output_dir="chunks"):
    """
    Divide audio file into chunks and save them to a directory
    """
    Path(output_dir).mkdir(parents=True, exist_ok=True)

    audio = AudioSegment.from_wav(input_file)
    base_filename = os.path.splitext(os.path.basename(input_file))[0]

    chunks = [audio[i:i + chunk_length_ms]
             for i in range(0, len(audio), chunk_length_ms)]

    chunk_files = []
    for i, chunk in enumerate(chunks):
        chunk_name = f"{base_filename}-chunk_{i:04d}.wav"
        chunk_path = os.path.join(output_dir, chunk_name)

        chunk.export(chunk_path, format="wav")
        chunk_files.append(chunk_path)

    return chunk_files

def extract_features_from_wav(wav_path):
    """
    Extract audio features from a single WAV file
    """
    y, sr = librosa.load(wav_path, mono=True, duration=30)

    # return {
    #     'filename': os.path.basename(wav_path),
    #     'chroma_stft_mean': np.mean(librosa.feature.chroma_stft(y=y, sr=sr)),
    #     'spectral_centroid_mean': np.mean(librosa.feature.spectral_centroid(y=y, sr=sr)),
    #     'spectral_bandwidth_mean': np.mean(librosa.feature.spectral_bandwidth(y=y, sr=sr)),
    #     'rolloff_mean': np.mean(librosa.feature.spectral_rolloff(y=y, sr=sr)),
    #     'zero_crossing_rate_mean': np.mean(librosa.feature.zero_crossing_rate(y=y)),
    # }
    # Extract MFCC features
    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)
    n_mfcc = 13
    # Add MFCC features to the dictionary
    mfcc_features = {}
    for i in range(n_mfcc):
        mfcc_features[f'mfcc{i+1}_mean'] = np.mean(mfcc[i])
        mfcc_features[f'mfcc{i+1}_std'] = np.std(mfcc[i])

    rest_of_the_features = {
        'filename': os.path.basename(wav_path),
        'chroma_stft_mean': np.mean(librosa.feature.chroma_stft(y=y, sr=sr)),
        'spectral_centroid_mean': np.mean(librosa.feature.spectral_centroid(y=y, sr=sr)),
        'spectral_bandwidth_mean': np.mean(librosa.feature.spectral_bandwidth(y=y, sr=sr)),
        'rolloff_mean': np.mean(librosa.feature.spectral_rolloff(y=y, sr=sr)),
        'zero_crossing_rate_mean': np.mean(librosa.feature.zero_crossing_rate(y=y)),
    }

    # Combine all features
    all_features = {**rest_of_the_features, **mfcc_features}

    return all_features

def create_feature_df(wav_path, chunk_length_ms, chunks_dir):
    all_features = []
    # Chunk the audio file
    chunk_files = chunk_audio_file(
        wav_path,
        chunk_length_ms=chunk_length_ms,
        output_dir=chunks_dir
    )

    # Extract features for each chunk
    for chunk_file in chunk_files:
        features = extract_features_from_wav(chunk_file)
        #features['original_wav'] = file
        all_features.append(features)
        #print(f"Processed chunk: {chunk_file}")

        # Convert features to DataFrame
    features_df = pd.DataFrame(all_features)

    return features_df

# def process_audio_file(audio_path, sr=22050, duration=None):
#     """
#     Process a single audio file and extract the same features used in training
#     """
#     # Load audio file
#     y, sr = librosa.load(audio_path)

#     # Extract features (make sure these are the same features you used for training)
#     features = {
#         'rms': np.mean(librosa.feature.rms(y=y)),
#         'zero_crossing_rate': np.mean(librosa.feature.zero_crossing_rate(y=y)),
#         'spectral_centroid': np.mean(librosa.feature.spectral_centroid(y=y, sr=sr)),
#         'spectral_rolloff': np.mean(librosa.feature.spectral_rolloff(y=y, sr=sr)),
#         'spectral_bandwidth': np.mean(librosa.feature.spectral_bandwidth(y=y, sr=sr))
#         # Add any other features you used during training
#     }

#     return pd.DataFrame([features])

def predict_drone(audio_path, model, chunk_length_ms, chunks_dir):
    """
    Predict whether an audio file contains drone noise
    """
    # Process the audio file
    #features_df = process_audio_file(audio_path)
    features_df = create_feature_df(audio_path, chunk_length_ms, chunks_dir)
    #print(features_df.head())
    features_df = features_df.drop(columns=["filename"])
    features_df.to_csv("recorded_features.csv")

    # Make prediction
    prediction = model.predict(features_df)
    probability = model.predict_proba(features_df)
    #print(probability)
    # print(type(prediction))
    print(prediction)
    majority_label = np.bincount(prediction).argmax()
    # print(majority_label)
    #majority_label = max(l)

    # Calculate mean of each column
    label_0_prob_mean = np.mean(probability[:, 0])   # First column
    label_1_prob_mean = np.mean(probability[:, 1])  # Second column

    if majority_label == 1:
      conf = label_1_prob_mean
    else:
      conf = label_0_prob_mean

    plot_audio_signal_and_prediction(audio_path, prediction)
    return {
        #'is_drone': bool(prediction[0]),
        'is_drone': bool(majority_label),
        #'confidence': probability[0][1] if prediction[0] else probability[0][0]
        'confidence': conf
    }

# Example usage:
def main():
    # Load your trained model and scaler (assuming you saved them)
    import joblib

    # Load the saved model and scaler
    model = joblib.load('drone_detector_model.joblib')

    # Test on new audio file
    audio_path = "/content/20no_20yes_20no.wav"
    chunk_length_ms = 1000
    chunks_dir = "chunks"
    result = predict_drone(audio_path, model, chunk_length_ms, chunks_dir)

    # if result['is_drone']:
    #     print(f"Drone detected with {result['confidence']*100:.2f}% confidence")
    # else:
    #     print(f"No drone detected with {result['confidence']*100:.2f}% confidence")

# # Save your model and scaler (do this after training)
# import joblib
# joblib.dump(clf_svm, 'drone_detector_model.joblib')


if __name__ == "__main__":
    main()

